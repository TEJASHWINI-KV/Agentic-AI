{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhKQ2zYApOOW",
        "outputId": "0f064b76-0cf1-4ddb-efaa-89ac811f9252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install -qU langchain langchain-google-genai google-generativeai==0.8.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "_ImJTlWEpWeM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "6VACpg8EpY-E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.7,\n",
        "    convert_system_message_to_human=True\n",
        ")"
      ],
      "metadata": {
        "id": "EcoLuYujpcHu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up windowed memory (keep only last 2 turns)\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    input_key=\"input\",\n",
        "    output_key=\"text\",\n",
        "    k=2,  # Only last 2 messages remembered\n",
        "    return_messages=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRwSG2a5pktM",
        "outputId": "1fd7f95a-9deb-4fee-e19a-24cc46f8cb99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2748091424.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferWindowMemory(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Chat History: {chat_history}\\n\\nHuman: {input}\\nAI:\",\n",
        "    input_variables=[\"input\"],\n",
        ")"
      ],
      "metadata": {
        "id": "hOAMwGu9poRQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain with memory\n",
        "chat_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    output_key=\"text\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJWGijnXpsqb",
        "outputId": "39724ebd-9501-424b-a08b-27dca358e0bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-850833841.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chat_chain = LLMChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Name input\n",
        "name = input(\"Enter your name: \")\n",
        "chat_chain.invoke({\"input\": f\"My name is {name}. Please remember it and greet me.\"})\n",
        "\n",
        "# Step 2: Topic 1\n",
        "#chat_chain.invoke({\"input\": \"Tell me something interesting about Mars.\"})\n",
        "topic1 = chat_chain.invoke({\"input\": \"Tell me something interesting about Mars.\"})\n",
        "print(\"\\n  Topic 1:\\n\", topic1[\"text\"])\n",
        "\n",
        "# Step 3: Topic 2\n",
        "topic2 = chat_chain.invoke({\"input\": \"Now explain how plants make food.\"})\n",
        "print(\"\\n  Topic 2:\\n\", topic2[\"text\"])\n",
        "\n",
        "# Step 4: Topic 3\n",
        "topic3 = chat_chain.invoke({\"input\": \"Now explain Where do we apply calculus in Data Science?.\"})\n",
        "print(\"\\n  Topic 3:\\n\", topic3[\"text\"])\n",
        "\n",
        "# Step 4: Ask if it still remembers the name (it won’t!)\n",
        "followup = chat_chain.invoke({\"input\": \"Do you remember my name?\"})\n",
        "\n",
        "print(\"\\n Follow-up Response:\\n\", followup[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulVtuaWqpv2O",
        "outputId": "a82b8e0c-1187-47c6-b964-b8d76df7c001"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your name: Mike\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mChat History: [HumanMessage(content='Now explain how plants make food.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Okay, Mike! Plants make their own food through a process called photosynthesis. Here's a simplified explanation:\\n\\n1.  **Ingredients:** Plants need three main ingredients:\\n    *   **Sunlight:** This provides the energy for the process.\\n    *   **Carbon Dioxide (CO2):** Plants absorb this gas from the air through tiny holes on their leaves called stomata.\\n    *   **Water (H2O):** Plants absorb water from the soil through their roots.\\n\\n2.  **The Magic Happens (Photosynthesis):** Inside the leaves, within structures called chloroplasts, there's a green pigment called chlorophyll. Chlorophyll captures the energy from sunlight.\\n\\n3.  **The Recipe:** Chlorophyll uses the sunlight's energy to convert carbon dioxide and water into glucose (a type of sugar). This is the plant's food.\\n\\n4.  **The Byproduct:** As a byproduct of photosynthesis, plants release oxygen (O2) into the atmosphere. This is the oxygen we breathe!\\n\\nSo, in simple terms:\\n\\nSunlight + Carbon Dioxide + Water --> Glucose (Food) + Oxygen\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Mike!', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Human: My name is Mike. Please remember it and greet me.\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mChat History: [HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Mike!', additional_kwargs={}, response_metadata={}), HumanMessage(content='My name is Mike. Please remember it and greet me.', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay, Mike!', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Human: Tell me something interesting about Mars.\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "  Topic 1:\n",
            " Mars has the largest volcano and the deepest, longest canyon in the solar system.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mChat History: [HumanMessage(content='My name is Mike. Please remember it and greet me.', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay, Mike!', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me something interesting about Mars.', additional_kwargs={}, response_metadata={}), AIMessage(content='Mars has the largest volcano and the deepest, longest canyon in the solar system.', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Human: Now explain how plants make food.\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "  Topic 2:\n",
            " Plants make their own food through a process called photosynthesis. Here's a simplified explanation:\n",
            "\n",
            "*   **They take in sunlight:** Plants have a pigment called chlorophyll, which captures light energy from the sun.\n",
            "*   **They absorb water:** Plants draw water from the soil through their roots.\n",
            "*   **They take in carbon dioxide:** Plants absorb carbon dioxide from the air through tiny pores on their leaves called stomata.\n",
            "*   **Photosynthesis occurs:** Inside the chloroplasts (structures containing chlorophyll), the light energy, water, and carbon dioxide are combined. This process converts these ingredients into glucose (a type of sugar), which is the plant's food.\n",
            "*   **Oxygen is released:** As a byproduct of photosynthesis, plants release oxygen into the atmosphere.\n",
            "\n",
            "So, in essence, plants use sunlight, water, and carbon dioxide to create their own food (glucose) and release oxygen.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mChat History: [HumanMessage(content='Tell me something interesting about Mars.', additional_kwargs={}, response_metadata={}), AIMessage(content='Mars has the largest volcano and the deepest, longest canyon in the solar system.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Now explain how plants make food.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Plants make their own food through a process called photosynthesis. Here's a simplified explanation:\\n\\n*   **They take in sunlight:** Plants have a pigment called chlorophyll, which captures light energy from the sun.\\n*   **They absorb water:** Plants draw water from the soil through their roots.\\n*   **They take in carbon dioxide:** Plants absorb carbon dioxide from the air through tiny pores on their leaves called stomata.\\n*   **Photosynthesis occurs:** Inside the chloroplasts (structures containing chlorophyll), the light energy, water, and carbon dioxide are combined. This process converts these ingredients into glucose (a type of sugar), which is the plant's food.\\n*   **Oxygen is released:** As a byproduct of photosynthesis, plants release oxygen into the atmosphere.\\n\\nSo, in essence, plants use sunlight, water, and carbon dioxide to create their own food (glucose) and release oxygen.\", additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Human: Now explain Where do we apply calculus in Data Science?.\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "  Topic 3:\n",
            " Calculus plays a crucial role in various aspects of Data Science, even if it's not always explicitly used in day-to-day coding. Here's a breakdown of where calculus finds its application:\n",
            "\n",
            "*   **Optimization Algorithms:** Many machine learning algorithms rely on optimization techniques to find the best parameters for a model. Calculus is essential for understanding and implementing these algorithms. Gradient descent, a fundamental optimization algorithm, relies on finding the minimum of a cost function using derivatives.\n",
            "\n",
            "*   **Probability and Statistics:** Calculus is fundamental to understanding probability distributions (e.g., normal distribution, exponential distribution). Concepts like probability density functions (PDFs) and cumulative distribution functions (CDFs) are defined using integrals. Statistical inference and hypothesis testing often involve calculus-based calculations.\n",
            "\n",
            "*   **Model Building:** In certain machine learning models, particularly those involving continuous functions, calculus is used to define and analyze the model. For example, neural networks rely on backpropagation, which is based on the chain rule of calculus, to adjust the weights of the network.\n",
            "\n",
            "*   **Data Analysis:** Calculus can be used to analyze trends and patterns in data. For example, derivatives can be used to find the rate of change of a variable over time.\n",
            "\n",
            "*   **Dimensionality Reduction:** Techniques like Principal Component Analysis (PCA) often involve eigenvalue decomposition, which has links to calculus through linear algebra and optimization.\n",
            "\n",
            "*   **Understanding Machine Learning Algorithms:** A deep understanding of calculus helps in understanding the inner workings of many machine learning algorithms, allowing for better model selection, hyperparameter tuning, and troubleshooting.\n",
            "\n",
            "In summary, while you might not be directly calculating derivatives or integrals every day as a data scientist, a solid foundation in calculus is essential for comprehending the underlying principles of many algorithms and techniques used in the field.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mChat History: [HumanMessage(content='Now explain how plants make food.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Plants make their own food through a process called photosynthesis. Here's a simplified explanation:\\n\\n*   **They take in sunlight:** Plants have a pigment called chlorophyll, which captures light energy from the sun.\\n*   **They absorb water:** Plants draw water from the soil through their roots.\\n*   **They take in carbon dioxide:** Plants absorb carbon dioxide from the air through tiny pores on their leaves called stomata.\\n*   **Photosynthesis occurs:** Inside the chloroplasts (structures containing chlorophyll), the light energy, water, and carbon dioxide are combined. This process converts these ingredients into glucose (a type of sugar), which is the plant's food.\\n*   **Oxygen is released:** As a byproduct of photosynthesis, plants release oxygen into the atmosphere.\\n\\nSo, in essence, plants use sunlight, water, and carbon dioxide to create their own food (glucose) and release oxygen.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Now explain Where do we apply calculus in Data Science?.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Calculus plays a crucial role in various aspects of Data Science, even if it's not always explicitly used in day-to-day coding. Here's a breakdown of where calculus finds its application:\\n\\n*   **Optimization Algorithms:** Many machine learning algorithms rely on optimization techniques to find the best parameters for a model. Calculus is essential for understanding and implementing these algorithms. Gradient descent, a fundamental optimization algorithm, relies on finding the minimum of a cost function using derivatives.\\n\\n*   **Probability and Statistics:** Calculus is fundamental to understanding probability distributions (e.g., normal distribution, exponential distribution). Concepts like probability density functions (PDFs) and cumulative distribution functions (CDFs) are defined using integrals. Statistical inference and hypothesis testing often involve calculus-based calculations.\\n\\n*   **Model Building:** In certain machine learning models, particularly those involving continuous functions, calculus is used to define and analyze the model. For example, neural networks rely on backpropagation, which is based on the chain rule of calculus, to adjust the weights of the network.\\n\\n*   **Data Analysis:** Calculus can be used to analyze trends and patterns in data. For example, derivatives can be used to find the rate of change of a variable over time.\\n\\n*   **Dimensionality Reduction:** Techniques like Principal Component Analysis (PCA) often involve eigenvalue decomposition, which has links to calculus through linear algebra and optimization.\\n\\n*   **Understanding Machine Learning Algorithms:** A deep understanding of calculus helps in understanding the inner workings of many machine learning algorithms, allowing for better model selection, hyperparameter tuning, and troubleshooting.\\n\\nIn summary, while you might not be directly calculating derivatives or integrals every day as a data scientist, a solid foundation in calculus is essential for comprehending the underlying principles of many algorithms and techniques used in the field.\", additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Human: Do you remember my name?\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            " Follow-up Response:\n",
            " As a large language model, I don't have memory of past conversations or personal information like your name.\n"
          ]
        }
      ]
    }
  ]
}